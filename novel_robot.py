#!/usr/bin/python3
# -*- coding: utf-8 -*-

"""A web robot that is used to collect and download novels."""

from collections import deque
import re
import sys
import requests

__author__     = 'EternalPhane'
__copyright__  = 'Copyright (c) 2016 EternalPhane'
__license__    = 'MIT'
__version__    = '0.0.1'
__maintainer__ = 'EternalPhane'
__email__      = 'eternalphane@gmail.com'
__status__     = 'Prototype'


def main(argv):
    """Main function."""
    site = 'www.biquge.la'
    title = '巫师世界'
    global HEADERS, RE_BAIDU_URL, RE_URL, RE_TITLE, RE_CONTENTS, RE_CHAPTER, VERBOSE
    HEADERS = {
        'Connection': 'Keep-Alive',
        'Accept': 'text/html,application/xhtml+xml,*/*',
        'Accept-Language': 'en-US,en;q=0.8,zh-Hans-CN;q=0.5,zh-Hans;q=0.3',
        'User-Agent': (
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) '
            'AppleWebKit/537.36 (KHTML, like Gecko) '
            'Chrome/51.0.2704.63 Safari/537.36'
        )
    }
    RE_BAIDU_URL = re.compile(r'<a[\w\W]+?data-click[\w\W]+?href = "(http[^@\r\n]+?)"')
    RE_URL = re.compile(
        r'<a[\w\W]+?href[ ]?=[ ]?"(http[^@>\r\n]+?|/[^>\r\n]+?)"[\w\W]*?>([\w\W]*?)</a>'
    )
    RE_TITLE = re.compile(r'[《\r\n ]?%s[》\r\n ]?' % (title))
    RE_CONTENTS = re.compile(r'<a href="(.+?)".*?(目录|阅读).*?</a>')
    RE_CHAPTER = re.compile(r'<a href="(.+?)".*?([一二三四五六七八九十百千0-9]+[章节 ]).*?</a>')
    VERBOSE = False
    process_argv(argv)
    url_contents = direct_novel(site, title)
    if not url_contents:
        print('Novel not found.')
    contents = get_contents(url_contents)
    print(contents)


def process_argv(argv):
    """Processes argv."""
    if '-v' in argv:
        global VERBOSE
        VERBOSE = True


def get_request(url):
    """Wrapped function of requests.get()."""
    return requests.get(url, headers=HEADERS)


def get_true_url(url):
    """Gets the redirected url of given url."""
    return requests.head(url, headers=HEADERS, allow_redirects=True).url


def direct_novel(site, title):
    """Directs to novel contents webpage.

    Searches the url of specific novel`s contents page according to its title on given website.

    Args:
      site: A string contains the url of website.
      title: A string contains the title of novel.

    Returns:
      A string contains the url of novel`s contents, None if not found.
    """
    url = requests.get('https://www.baidu.com/s', params={'wd': '%s site:%s' % (title, site)}).url
    queue = deque()
    queue.append(url)
    visited = set()
    url = queue.popleft()
    visited.add(url)
    print('caught: 0    analyzing <-- %s' % (url))
    cnt = 1
    resp = get_request(url)
    for url in RE_BAIDU_URL.findall(resp.text):
        try:
            url = get_true_url(url)
            if url not in visited:
                queue.append(url)
                if VERBOSE:
                    print('appending to queue --> %s' % (url))
        except:
            continue
    while queue:
        url = queue.popleft()
        visited.add(url)
        print('caught: %d    analyzing <-- %s' % (cnt, url))
        cnt += 1
        resp = get_request(url)
        if 'html' not in resp.headers['Content-Type']:
            continue
        if RE_TITLE.search(resp.text):
            url_contents = check_contents_url(resp)
            if url_contents:
                return url_contents
        #print(resp.content.decode('gb2312'))
        urls = RE_URL.findall(resp.text)
        for url in urls:
            try:
                if re.match('/', url[0]):
                    url = [x for x in url]
                    url[0] = 'http://' + site + url[0]
                if url[0] not in visited:
                    queue.append(url[0])
                    visited.add(url[0])
                    if VERBOSE:
                        print('appending to queue --> %s' % (url[0]))
            except:
                continue


def check_contents_url(resp):
    """Checks if a url refers to the contents page of specific novel.

    Checks whether a url refers to specific novel`s contents page, description page or any other
    page. If it refers to the description page, search for the url of the novel`s contents page on
    the description page.

    Args:
      resp: A Response object generated by a url.

    Returns：
      A string contains the url of specific novel`s contents page, None if the url refers to any
      other page.
    """
    if 'html' not in resp.headers['Content-Type']:
        return None
    str_title = RE_TITLE.search(resp.text)
    url_chapter = RE_CHAPTER.findall(resp.text)
    url_contents = RE_CONTENTS.search(resp.text)
    if str_title and url_chapter and len(url_chapter) > 1:
        return resp.url
    if url_contents:
        return check_contents_url(get_request(url_contents.groups()[0]))
    return None


def get_contents(url):
    """Gets the contents of a novel.

    Generates a dict contains the contents and the urls refer to the chapters of specific novel.

    Args:
      url: A string contains the url of specific novel`s contents.

    Returns:
      A dict with chapter names as its keys and urls refer to chapters as its value.
    """
    # TODO(EternalPhane): Complete get_contents after fixed the bugs in direct_novel.
    contents = {}
    return contents


if __name__ == '__main__':
    main(sys.argv)
